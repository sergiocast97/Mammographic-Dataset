length(unique(df$Severity))
# Showing unique labels
unique(df$Severity)
# Finding out missing values
sum(is.na(df))
sum(is.na(df$Assessment))
sum(is.na(df$Age))
sum(is.na(df$Shape))
sum(is.na(df$Margin))
sum(is.na(df$Density))
sum(is.na(df$Severity))
# Class distribution
severityFreq <- table(df$Severity)
barplot(
severityFreq,
col = c('steelblue4','coral1'),
main="Severity Frequency",
names.arg=c("Benign","Malicious"),
ylab="Number of patients"
)
# Converting into categorical
df$Assessment <- factor(df$Assessment)
df$Shape      <- factor(df$Shape)
df$Margin     <- factor(df$Margin)
df$Density    <- factor(df$Density, order=TRUE, levels=c("1","2","3","4"))
df$Severity   <- factor(df$Severity)
# Summary for every attribute
summary(df$Assessment)
summary(df$Age)
summary(df$Shape)
summary(df$Margin)
summary(df$Density)
summary(df$Severity)
# Finding how attributes compare to goal
plot(
data = df,
Age~Severity,
col = c('steelblue4','coral1'),
names.arg=c("Benign","Malicious")
)
# Fiding how attributes compare to age
library(datasets)
data <- transform(df, Shape)
boxplot(Age~Shape, data,xlab="Shape",ylab="Age")
data <- transform(df, Margin)
boxplot(Age~Margin, data,xlab="Margin",ylab="Age")
data <- transform(df, Density)
boxplot(Age~Density, data,xlab="Density",ylab="Age")
# Histograms
Age <- df$Age
hist(
Age,
xlab="Patient Age",
col="turquoise3",
)
# Filling misssing values with mean
fillMissings <- function(x) { replace( x, is.na(x), mean(x[!is.na(x)])) }
df$Age <- fillMissings(df$Age)
sum(is.na(df$Age))
# Drop useless column
# Backing up the data frame
df_clean <- df
# Dropping the irrelevant column
df_clean$Assessment <- NULL
# Showing the data frame columns without the dropped one
names(df_clean)
# Deleting rows with misssing factor attributes
df_clean <- df_clean[!is.na(df_clean$Shape),]
df_clean <- df_clean[!is.na(df_clean$Margin),]
df_clean <- df_clean[!is.na(df_clean$Density),]
sum(is.na(df_clean))
nrow(df_clean)
# Dividing the dataset into train and test
library(ISLR)
library(dplyr)
train<-sample_frac( df_clean, 0.7)
nrow(train)
sid<-as.numeric(rownames(train))
test <- df_clean[-sid,]
nrow(test)
# Regression Model
logit.model <- glm(
Severity ~ Age+Shape+Margin+Density,
data=train,
family=binomial
)
summary(logit.model)
# Regression Model
regressionModel <- glm(
Severity ~ Age+Shape+Margin+Density,
data=train,
family=binomial
)
summary(regressionModel)
# Regression Model
regressionModel <- glm(
Severity ~ Age+Shape+Margin+Density,
data=train,
family=binomial
)
summary(regressionModel)
summary(regressionModel)
predicted values <- as.integer(regressionModel$fitted.values > 0.5)
predictedValues <- as.integer(regressionModel$fitted.values > 0.5)
(error <- mean(predictedValues != train$severity))
predictedValues
(error <- mean(predictedValues != train$Severity))
( accuracy <- (1 - error) * 100)
abline(regressionModel)
abline(regressionModel)
# Prediction
predict(
regressionModel,
new,
interval="confidence")
# Prediction
predict(
regressionModel,
test,
interval="confidence"
)
# Prediction
predict(
regressionModel,
test,
interval="prediction"
)
# Prediction
predict(
regressionModel,
test,
interval="prediction="
)
# Prediction
predict(
regressionModel,
test,
interval="prediction"
)
# Prediction
predict(
regressionModel,
test,
interval="prediction"
)
help
predict??
xz
predict--help
help(predict)
# Prediction
predict(
regressionModel,
test,
# interval="prediction"
)
# Prediction
predict(
regressionModel,
test[12],
interval="prediction"
)
# Prediction
predictions<-predict(
regressionModel,
test,
type="response"
)
predictions[1:10]
head(table(predictions,test$Severity))
# Prediction
probabilities <- predict(
regressionModel,
newdata=subset(test,select=c(2,3,4)),
type="response"
)
sum(is.na(df_clean))
nrow(df_clean)
names(df_clean)
# Prediction
probabilities <- predict(
regressionModel,
newdata=subset(test,select=c(0,1,2,3,4)),
type="response"
)
predictions <- ifelse(probabilities>0.5,"Yes","No")
test_accuracy <- mean(predictions==test$Severity)
test_accuracy
# Prediction
probabilities <- predict(
regressionModel,
newdata=subset(test,select=c(0,1,2,3)),
type="response"
)
# Prediction
probabilities <- predict(
regressionModel,
newdata=subset(test,select=c(1,2,3,4)),
type="response"
)
predictions <- ifelse(probabilities>0.5,"Yes","No")
test_accuracy <- mean(predictions==test$Severity)
test_accuracy
predictions <- ifelse(probabilities>0.5, 1, 0)
test_accuracy <- mean(predictions==test$Severity)
test_accuracy
install.packages("ROCR")
# ROC Model
library(ROCR)
pr <- prediction(probabilities, test$Severity)
performance <- performance( pr, measure = "tpr", x.measure = "fpr")
plot(prf,frame=FALSE)
prf <- performance( pr, measure = "tpr", x.measure = "fpr")
plot(prf,frame=FALSE)
# area under the curve
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
plot(prf)
plot(prf)
,frame=FALSE
plot(prf,frame=FALSE)
install.packages("caret")
install.packages("missForest")
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
sum(is.na(newDF$Age))
# Missing values
prodNA(newDF, noNA = 0.1)
# Missing values
newDF<-prodNA(newDF, noNA = 0.1)
library(missForest)
# Missing values
newDF<-prodNA(newDF, noNA = 0.1)
summary(newDF)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
newDF<-prodNA(newDF, noNA = 0.1)
summary(newDF)
newDF <- missForest(newDF)
summary(newDF)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
newDF<-prodNA(newDF, noNA = 0.1)
summary(newDF)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
# Missing values
summary(newDF)
nrow(newDf)
nrow(newDF)
newDF<-prodNA(newDF, noNA = 0.1)
summary(newDF)
nrow(newDF)
sum(is.na(df_clean))
nrow(df_clean)
# Missing values
summary(newDF)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
newDF<-prodNA(newDF, noNA = 0.1)
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
newDF <- missForest(newDF)
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
missForest(newDF)
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
summary(newDF)
summary(newDF)
# Missing values
nrow(newDF)
sum(is.na(newDF))
newDFimputed <- missForest(newDF)
newDF <- df
library(missForest)
library(caret)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
newDFimputed <- missForest(newDF)
summary(newDF)
nrow(newDF)
sum(is.na(newDF))
install.packages("mice")
library(caret)
library(mice)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
# Impute missing values using MICE
newDF <- mice(newDF, m=5, maxit = 50, method = 'polyreg', seed = 500)
sum(is.na(newDF))
summary(newDF)
summary(newDF)
summary(newDF)
# Impute missing values using MICE
newDF <- mice(newDF, m=1, maxit = 5, method = 'polyreg', seed = 500)
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
# Impute missing values using MICE
newDF <- mice(newDF, m=1, maxit = 5, method = 'polyreg', seed = 500)
newDF <- complete(newDF,0)
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
newDF <- df
newDF$Assessment <- NULL
newDF$Age <- fillMissings(newDF$Age)
# Missing values
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
# Impute missing values using MICE
newDF <- mice(newDF, m=1, maxit = 5, method = 'polyreg', seed = 500)
newDF <- complete(newDF,1)
nrow(newDF)
summary(newDF)
sum(is.na(newDF))
install.packages("mice")
new_df <- df
new_df$Assessment <- NULL
new_df$Age <- fillMissings(new_df$Age)
# Missing values
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
# Impute missing values using MICE
new_df <- mice(new_df, m=1, maxit=10, method='polyreg', seed=500)
new_df <- complete(new_df,1)
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
inTrain <- createDataPartition(y=new_df$Severity, p=.7,list=FALSE)
training <- new_df[inTrain,]
validating <- new_df [-inTrain,]
inTrain <- createDataPartition(y=new_df$Severity, p=.7,list=FALSE)
new_training <- new_df[inTrain,]
nrow(new_training)
new_validating <- new_df [-inTrain,]
nrow(new_validating)
new_df <- df
new_df$Assessment <- NULL
new_df$Age <- fillMissings(new_df$Age)
# Missing values
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
# Impute missing values using MICE
new_df <- mice(new_df, m=1, maxit=10, method='polyreg', seed=500)
new_df <- complete(new_df,1)
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
# Cross Validation
train_control<- trainControl(
method="cv", # Use the Cross Validation Method
number=10    # Divide into 10 subsets
)
summary(train_control)
# Random Foresr
# train the model
mymodel<- train(
Severity~.,
data=new_df,
trControl=train_control,
method="rf",
family=binomial()
)
library(caret)
# Random Forest
mymodel<- train(
Severity~.,
data=new_df,
trControl=train_control,
method="rf",
family=binomial()
)
library(e1071)
library(e1071)
# Random Forest
mymodel<- train(
Severity~.,
data=new_df,
trControl=train_control,
method="rf",
family=binomial()
)
summary(myModel)
rf_random <- train(Severity~., data=new_df, method="rf", metric=metric, tuneLength=15, trControl=train_control)
rf_random <- train(Severity~., data=new_df, method="rf", tuneLength=15, trControl=train_control)
install.packages('e1071', dependencies=TRUE)
# Random Forest
randomForestModel<- train(
Severity~.,
data=new_df,
trControl=train_control,
method="rf",
family=binomial()
)
summary(randomForestModel)
dede
nrow(new_training)
new_df <- df
new_df$Assessment <- NULL
new_df$Age <- fillMissings(new_df$Age)
# Missing values
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
# Impute missing values using MICE
new_df <- mice(new_df, m=1, maxit=10, method='polyreg', seed=500)
new_df <- complete(new_df,1)
nrow(new_df)
summary(new_df)
sum(is.na(new_df))
# Create a partition, to reserve a validation subset for later testing
inTrain <- createDataPartition(
y=new_df$Severity, # Have Severity as the classifying value
p=0.8,             # Assign 80% of the data to training
list=FALSE
)
# Generating the training subset
new_training <- new_df[inTrain,]
nrow(new_training)
# Generating the validating subset
new_validating <- new_df [-inTrain,]
nrow(new_validating)
# Cross Validation
train_control<- trainControl(
method="cv", # Use the Cross Validation Method
number=10    # Divide into 10 subsets
)
# Random Forest
randomForestModel<- train(
Severity~.,
data=new_training,
trControl=train_control,
method="rf",
family=binomial()
)
print(randomForestModel)
View(test)
# Random Forest
randomForestModel<- train(
Severity~.,
data=new_training,
trControl=train_control,
method="ranger",
family=binomial()
)
# Random Forest
randomForestModel<- train(
Severity~.,
data=new_training,
trControl=train_control,
method="ranger",
family=binomial()
)
